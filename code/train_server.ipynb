{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. 跑 combine_channel.py， 生成 output.tif",
   "id": "a87fe4fdce26ebd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. 跑这个 notebook 里面的代码",
   "id": "f0a00e88156958db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(3407)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(3407)\n",
    "random.seed(3407)"
   ],
   "id": "a22bed66813e67be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from tif2pngs import ROOT\n",
    "import os\n",
    "\n",
    "combined_file_path = os.path.join(ROOT, 'datasets', 'main', 'result.tif') # TODO\n",
    "root_path = ROOT\n",
    "\n",
    "with rasterio.open(combined_file_path) as src:\n",
    "    print(src.meta)\n",
    "    width = src.meta['width']\n",
    "    height = src.meta['height']\n",
    "    channels = src.meta['count']\n",
    "    # 分块保存ndarray，每块大小为 256 * 256\n",
    "    block_size = 256\n",
    "    for i in range(0, height, block_size // 2):\n",
    "        for j in range(0, width, block_size // 2):\n",
    "            block = src.read(window=(\n",
    "                (i, min(i + block_size, height)),\n",
    "                (j, min(j + block_size, width)))\n",
    "            )\n",
    "            \n",
    "            if block.shape[1:] != (block_size, block_size):\n",
    "                pad_height = block_size - block.shape[1]\n",
    "                pad_width = block_size - block.shape[2]\n",
    "                block = np.pad(block, ((0, 0), (0, pad_height), (0, pad_width)), mode='constant')\n",
    "            \n",
    "            # 保存 block 数组\n",
    "            np.save(f'{root_path}/dataV2/train/blocks/block_{i}_{j}.npy', block)"
   ],
   "id": "28b3177885c42ab7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "combined_file_path = '' # TODO\n",
    "root_path = '' # TODO\n",
    "\n",
    "with rasterio.open(combined_file_path) as src:\n",
    "    print(src.meta)\n",
    "    width = src.meta['width']\n",
    "    height = src.meta['height']\n",
    "    channels = src.meta['count']\n",
    "    # 分块保存ndarray，每块大小为 256 * 256\n",
    "    block_size = 256\n",
    "    for i in range(0, height, block_size // 4):\n",
    "        for j in range(0, width, block_size // 4):\n",
    "            block = src.read(window=(\n",
    "                (i, min(i + block_size, height)),\n",
    "                (j, min(j + block_size, width)))\n",
    "            )\n",
    "            \n",
    "            if block.shape[1:] != (block_size, block_size):\n",
    "                pad_height = block_size - block.shape[1]\n",
    "                pad_width = block_size - block.shape[2]\n",
    "                block = np.pad(block, ((0, 0), (0, pad_height), (0, pad_width)), mode='constant')\n",
    "            \n",
    "            # 保存 block 数组\n",
    "            np.save(f'{root_path}/dataV2/train/blocks/block_{i}_{j}.npy', block)"
   ],
   "id": "b1e78f0451e97e9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tif2pngs import Tif2Pngs\n",
    "import os\n",
    "\n",
    "\n",
    "mask_file_path = os.path.join(root_path, 'datasets', 'standard.tif')\n",
    "tif2pngs = Tif2Pngs(mask_file_path, os.path.join(root_path, 'dataV2', 'train', 'masks'), stride=64)\n",
    "tif2pngs.process_tif()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from albumentations import Compose, HorizontalFlip, VerticalFlip, ShiftScaleRotate, RandomResizedCrop\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from tif2pngs import ROOT\n",
    "\n",
    "# 数据增强方法\n",
    "transform = Compose([\n",
    "    HorizontalFlip(p=0.5),  # 随机水平翻转\n",
    "    VerticalFlip(p=0.5),  # 随机垂直翻转\n",
    "    ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.5),  # 随机仿射变换\n",
    "    RandomResizedCrop(height=256, width=256, scale=(0.6, 1.0), p=0.5),  # 随机裁剪和调整大小\n",
    "    # OneOf([\n",
    "    #     MotionBlur(p=0.2),\n",
    "    #     MedianBlur(blur_limit=3, p=0.1),\n",
    "    #     Blur(blur_limit=3, p=0.1),\n",
    "    # ], p=0.5),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# 数据增强函数\n",
    "def augment_npy_images(image_path, mask_path, save_dir, transform):\n",
    "    # 加载 .npy 格式的图像和 .png 格式的掩码\n",
    "    image = np.load(image_path)  # 加载 block 数据，形状 (C, H, W)\n",
    "    image = np.moveaxis(image, 0, -1)  # 转换为 (H, W, C)\n",
    "    mask = np.array(Image.open(mask_path))  # 掩码保持单通道格式\n",
    "\n",
    "    # 筛选掩码：仅处理包含两种及以上类别的掩码\n",
    "    unique_classes = np.unique(mask)\n",
    "    if len(unique_classes) < 2:\n",
    "        return\n",
    "\n",
    "    # 应用数据增强\n",
    "    augmented = transform(image=image, mask=mask)\n",
    "    transformed_image = augmented['image']  # 增强后的图像\n",
    "    transformed_mask = augmented['mask']    # 增强后的掩码\n",
    "\n",
    "    # 保存增强后的图像和掩码\n",
    "    save_image_path = os.path.join(save_dir, 'blocks', os.path.basename(image_path).replace('.npy', '_aug.npy'))\n",
    "    save_mask_path = os.path.join(save_dir, 'masks', os.path.basename(mask_path).replace('.png', '_aug.png'))\n",
    "\n",
    "    # 保存图像为 .npy 格式\n",
    "    np.save(save_image_path, transformed_image.numpy())\n",
    "    # 保存掩码为 .png 格式\n",
    "    Image.fromarray(transformed_mask.numpy()).save(save_mask_path)\n",
    "\n",
    "# 数据增强目录和逻辑\n",
    "def augment_dataset(source_dir, target_dir, transform):\n",
    "    os.makedirs(os.path.join(target_dir, 'blocks'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(target_dir, 'masks'), exist_ok=True)\n",
    "\n",
    "    image_files = os.listdir(os.path.join(source_dir, 'blocks'))\n",
    "    for image_file in tqdm(image_files, desc=\"Augmenting dataset\"):\n",
    "        if image_file.endswith('_aug.npy'):\n",
    "            continue\n",
    "        image_path = os.path.join(source_dir, 'blocks', image_file)\n",
    "        mask_path = os.path.join(source_dir, 'masks', image_file.replace('block', 'standard').replace('.npy', '.png'))\n",
    "\n",
    "        # 增强数据并保存到目标目录\n",
    "        augment_npy_images(image_path, mask_path, target_dir, transform)\n",
    "\n",
    "# 调用增强函数\n",
    "train_source_dir = os.path.join(root_path, 'dataV2', 'train')\n",
    "train_target_dir = os.path.join(root_path, 'dataV2', 'train')\n",
    "\n",
    "augment_dataset(train_source_dir, train_target_dir, transform)\n",
    "print(\"数据增强完成\")\n"
   ],
   "id": "aee908b2e7b9bb45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from SegmentationDatasetV2 import SegmentationDatasetV2\n",
    "\n",
    "train_dir = os.path.join(ROOT, 'dataV2', 'train')\n",
    "train_dataset = SegmentationDatasetV2(root_dir=train_dir)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ],
   "id": "f76e8dd87c4787e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from loss import FocalLoss\n",
    "import torch\n",
    "from segmentation_models_pytorch import Unet\n",
    "\n",
    "model_config = {\n",
    "    'model': Unet,\n",
    "    'encoder_name': 'resnet34',\n",
    "    'classes': 3,\n",
    "    'channels': 5,\n",
    "    'activation': 'softmax',\n",
    "}\n",
    "\n",
    "# 检查CUDA是否可用\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 创建模型\n",
    "model = model_config['model'](\n",
    "    encoder_name=model_config['encoder_name'],\n",
    "    classes=model_config['classes'],\n",
    "    in_channels=model_config['channels'],\n",
    "    activation=model_config['activation'],\n",
    ").to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "loss_fn = FocalLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 初始化最小loss为正无穷大\n",
    "min_loss = float('inf')\n",
    "\n",
    "# TODO 训练轮次改这里\n",
    "epoch_num = 50\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(1, epoch_num + 1):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        images, masks = batch\n",
    "        # 将数据和模型都移动到GPU\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # 现在masks是一个一维的tensor，每个元素对应一个像素的类别索引\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, masks)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # 每个epoch结束时保存模型\n",
    "    torch.save(model.state_dict(), f'../model/best_model_epoch_{epoch}.pth')\n",
    "    print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ],
   "id": "f313e214086c2ee8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
